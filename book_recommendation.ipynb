{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05e985b-15c5-461a-a7df-888558835f16",
   "metadata": {},
   "source": [
    "# Content-Based Filtering: NLP Based Book Recommender Using BERT-Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e42dc-e025-4527-9461-950c31b32790",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Amoli Rajgor\"\n",
    "__email__ = \"amoli.rajgor@gmail.com\"\n",
    "__website__ = \"amolir.github.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0389749-bf3c-4346-a82e-c0dfdbdbfa23",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- Content based filtering is one of the two common techniques of recommender systems. intelligible from the name, it uses the content of the entity (to be recommended) to find other relevant recommendations similar to it. In simpler terms the system finds the keywords or attributes related to the product that the user likes, later uses this information to recommend other products having similar attributes. \n",
    "- For a book recommendation system, given a book name the recommender will suggest books that are similar to it. The choice is made considering concise information of the book such as its theme, author, series, and summary of the description. \n",
    "\n",
    "## Book Recommendation System\n",
    "- The succinct data of keywords that is provided to the recommender system is generated using NLP techniques such as word embeddings.  Keywords that most describe the book are extracted from the book description using BERT-embeddings, this word collection is further reduced using the frequentist feature extraction method TF-IDF that ranks the words based on their frequency in the book and the corpus.     \n",
    "- Once the numeric vector representation of all the books is generated, each word vector is compared against the other vector and similar vectors (books) are found using cosine similarity.  \n",
    "   \n",
    "\n",
    "![architecture](../images/book_recommendation_system.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009bbfdb-197b-4393-9323-289efbeb68e6",
   "metadata": {},
   "source": [
    "---\n",
    "# Environment and Project Flow\n",
    "- The project pipeline is divided into three stages: \n",
    "1. [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](eda.ipynb) **Cleaning**\n",
    "2. [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](feature_engineering.ipynb) **Feature Extraction**\n",
    "3. [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](model.ipynb) **Modeling**\n",
    "\n",
    "- There’s a dedicated notebook for each of these stages containing detailed implementation of all intermediate steps. At the end of each stage the processed data is stored in the form of a CSV file. Current book will serve as a summarised representation of the project.\n",
    "- I will be using the following list of packages for the project.\n",
    "> <h4 style=\"color:blue\"> ℹ️ Dependencies </h4> <div style=\"background-color:#dbeaff\">  &#10148; numpy &ge; 1.22.3 <br> &#10148; pandas &ge; 1.4.1 <br> &#10148; scikit-learn &ge; 1.0.2 <br> &#10148; keybert &ge; 0.5.1 <br> &#10148; nltk &ge; 3.5 <br> &#10148; matplotlib &ge; 3.5.1 <br> &#10148; altair &ge; 4.2.0 <br> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c033531-a51b-49d2-8514-248b0a446487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# RegEx and String Manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Language Detection\n",
    "from nltk.classify.textcat import TextCat\n",
    "\n",
    "# BERT-Embeddings\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Plotting Heatmap of TF-IDF vectors \n",
    "import altair as alt\n",
    "\n",
    "# Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8fff2-1248-422e-b490-4fd9d9018a30",
   "metadata": {},
   "source": [
    "---\n",
    "# Text Cleaning\n",
    "- Remove books with missing **Description**.\n",
    "- Remove URLs and HTML tags from the **Description**.\n",
    "- Remove punctuations from the **Description**\n",
    "- Convert lowercase to lower for book **Name, Authors, Publishers** and **Description** and clip extra spaces.\n",
    "- Remove book descriptions with shorter length.\n",
    "- Remove variants of the same book.\n",
    "- Extract and remove book series information from the **Name** of the book.\n",
    "- Impute missing **Language** information using the language of the book **Name**.\n",
    "- Remove double quotes from **Publisher** name.\n",
    "- Transform Book **Name** and **Authors** into a single token.\n",
    "- Merge all the textual summary into a single summary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a0f57-a334-4053-a681-c492bd475fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b7153-9813-447c-8494-f27b66e58e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ef0af-b68d-47dc-9343-26b1560217e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0cfc007-f9ff-4267-886b-adcccaf16613",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36936a59-ce8b-40bc-ae9d-edef1cc64b46",
   "metadata": {},
   "source": [
    "## Keyword Extraction Using KeyBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26013de9-f621-42a0-9252-aacb0663a020",
   "metadata": {},
   "source": [
    "## Vectorization using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33b4dc-5c22-4afe-bd22-843bead63006",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264600a-f3a8-4919-b181-4233e839cd65",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb4799-6fd8-4ed0-a0a5-cf9c11e277ec",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
