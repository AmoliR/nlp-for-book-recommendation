{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05e985b-15c5-461a-a7df-888558835f16",
   "metadata": {},
   "source": [
    "# Content-Based Filtering: NLP Based Book Recommender Using BERT-Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e42dc-e025-4527-9461-950c31b32790",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Amoli Rajgor\"\n",
    "__email__ = \"amoli.rajgor@gmail.com\"\n",
    "__website__ = \"amolir.github.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0389749-bf3c-4346-a82e-c0dfdbdbfa23",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- Content based filtering is one of the two common techniques of recommender systems. intelligible from the name, it uses the content of the entity (to be recommended) to find other relevant recommendations similar to it. In simpler terms the system finds the keywords or attributes related to the product that the user likes, later uses this information to recommend other products having similar attributes. \n",
    "- For a book recommendation system, given a book name the recommender will suggest books that are similar to it. The choice is made considering concise information of the book such as its theme, author, series, and summary of the description. \n",
    "\n",
    "## Book Recommendation System\n",
    "- The succinct data of keywords that is provided to the recommender system is generated using NLP techniques such as word embeddings.  Keywords that most describe the book are extracted from the book description using BERT-embeddings, this word collection is further reduced using the frequentist feature extraction method TF-IDF that ranks the words based on their frequency in the book and the corpus.     \n",
    "- Once the numeric vector representation of all the books is generated, each word vector is compared against the other vector and similar vectors (books) are found using cosine similarity.  \n",
    "   \n",
    "\n",
    "![architecture](../images/book_recommendation_system.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009bbfdb-197b-4393-9323-289efbeb68e6",
   "metadata": {},
   "source": [
    "---\n",
    "# Environment and Project Flow\n",
    "- The project pipeline is divided into three stages: \n",
    "1. [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](eda.ipynb) **Cleaning**\n",
    "2. [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](feature_engineering.ipynb) **Feature Extraction**\n",
    "3. [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](model.ipynb) **Modeling**\n",
    "\n",
    "- There’s a dedicated notebook for each of these stages containing detailed implementation of all intermediate steps. At the end of each stage the processed data is stored in the form of a CSV file. Current book will serve as a summarised representation of the project.\n",
    "- I will be using the following list of packages for the project.\n",
    "> <h4 style=\"color:blue\"> ℹ️ Dependencies </h4> <div style=\"background-color:#dbeaff\">  &#10148; numpy &ge; 1.22.3 <br> &#10148; pandas &ge; 1.4.1 <br> &#10148; scikit-learn &ge; 1.0.2 <br> &#10148; keybert &ge; 0.5.1 <br> &#10148; nltk &ge; 3.5 <br> &#10148; matplotlib &ge; 3.5.1 <br> &#10148; altair &ge; 4.2.0 <br> &#10148; dask  &ge; 2022.4.1 <b> </div>\n",
    "    \n",
    "- Simply run `pip install requirements.txt’` from the terminal to install all the dependencies before running the notebook.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c033531-a51b-49d2-8514-248b0a446487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# RegEx and String Manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Language Detection\n",
    "from nltk.classify.textcat import TextCat\n",
    "\n",
    "# Multiprocessing\n",
    "import dask.dataframe as dd\n",
    "import multiprocessing\n",
    "\n",
    "# BERT-Embeddings\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Plotting Heatmap of TF-IDF vectors \n",
    "import altair as alt\n",
    "\n",
    "# Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d6bed6-90da-4d3e-b5a1-42e82dba7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of words that should be present in a description (value starting from 1)\n",
    "min_description_word_count = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0007720-a76d-4111-92a9-bb36c64e1a5d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Data\n",
    "- Dataset used for this project can be found [here](https://www.kaggle.com/datasets/bahramjannesarr/goodreads-book-datasets-10m?select=book1000k-1100k.csv). It is a [Goodreads](https://www.goodreads.com/) book  dataset containing book details and user rating of 10M books. As I am creating a POC project I will only be using data of 39705 books. It contains information such as book name, authors, publishers, publishing year, rating, description, review count, page number etc. I will only use the content that is needed to extract the book summary keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da572317-aaff-429c-a99b-8bddded6c926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39705, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Authors</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Language</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Flight from Eden</td>\n",
       "      <td>Kathryn A. Graham</td>\n",
       "      <td>0595199402</td>\n",
       "      <td>2001</td>\n",
       "      <td>Writer's Showcase Press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What could a computer expert, a mercenary with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Roommates Again</td>\n",
       "      <td>Kathryn O. Galbraith</td>\n",
       "      <td>0689505973</td>\n",
       "      <td>1994</td>\n",
       "      <td>Margaret K. McElderry Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>During their stay at Camp Sleep-Away, sisters ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>The King At The Door</td>\n",
       "      <td>Brock Cole</td>\n",
       "      <td>0374440417</td>\n",
       "      <td>1992</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A poorly dressed old man appears at an inn and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Giotto: The Scrovegni Chapel, Padua</td>\n",
       "      <td>Bruce Cole</td>\n",
       "      <td>080761310X</td>\n",
       "      <td>1993</td>\n",
       "      <td>George Braziller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This beautiful series lavishly illustrates the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>Larky Mavis</td>\n",
       "      <td>Brock Cole</td>\n",
       "      <td>0374343659</td>\n",
       "      <td>2001</td>\n",
       "      <td>Farrar, Straus and Giroux (BYR)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;b&gt;Another orginal picture-book fairy tale&lt;/b&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                 Name               Authors  \\\n",
       "0  1000000                     Flight from Eden     Kathryn A. Graham   \n",
       "1  1000001                      Roommates Again  Kathryn O. Galbraith   \n",
       "2  1000003                 The King At The Door            Brock Cole   \n",
       "3  1000004  Giotto: The Scrovegni Chapel, Padua            Bruce Cole   \n",
       "4  1000005                          Larky Mavis            Brock Cole   \n",
       "\n",
       "         ISBN  PublishYear                        Publisher Language  \\\n",
       "0  0595199402         2001          Writer's Showcase Press      NaN   \n",
       "1  0689505973         1994      Margaret K. McElderry Books      NaN   \n",
       "2  0374440417         1992             Farrar Straus Giroux      NaN   \n",
       "3  080761310X         1993                 George Braziller      NaN   \n",
       "4  0374343659         2001  Farrar, Straus and Giroux (BYR)      NaN   \n",
       "\n",
       "                                         Description  \n",
       "0  What could a computer expert, a mercenary with...  \n",
       "1  During their stay at Camp Sleep-Away, sisters ...  \n",
       "2  A poorly dressed old man appears at an inn and...  \n",
       "3  This beautiful series lavishly illustrates the...  \n",
       "4  <b>Another orginal picture-book fairy tale</b>...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data = pd.read_csv(\"data/goodreads_book.csv\", usecols=['Id', 'Name', 'Authors', 'ISBN', 'PublishYear', 'Publisher', 'Language', 'Description'])\n",
    "display(books_data.shape)\n",
    "books_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8fff2-1248-422e-b490-4fd9d9018a30",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "# Text Cleaning\n",
    "<span style=\"font-size:1.5em;\">Notebook:</span> [<span style=\"font-size:1.5em;\">eda.ipynb</span>](eda.ipynb)\n",
    "\n",
    "Text cleaning in NLP is the process of transforming the textual data into a format that is machine readable. Cleaning of the data is required to reduce the complexity of the model and increase its accuracy. We want to avoid processing irrelevant words and want the model to give equal weightage to the same words in spite of punctuations, letter case etc. Let's apply following steps to clean various features before performing keyword extraction onto it. Data is already processed ([Check eda.ipynb](eda.ipynb)) using these steps and results are store in `data/preprocessed.csv`.\n",
    "\n",
    "##  Remove books with Missing Description\n",
    "**Description** of the book becomes content for the recommendation engine. We want to extract keywords from the description of the book in such a case books with no description won’t add value to the model. However to avoid information loss in real scenario, missing descriptions can be filled with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abce169f-c697-41b3-b31b-f7706c740abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data.dropna(subset=[\"Description\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c967207-a38e-4ef7-b719-346d957a436a",
   "metadata": {},
   "source": [
    "## Remove URLs and HTML Tags and Punctuations from the Description.\n",
    "**Description** feature contains URLs, HTML tags and punctuations (example below). Let’s remove all this irrelevant textual information to refine it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "003166e3-2b8f-4ad7-8367-ad10c7c0c212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<i>Alternate Cover Edition can be found <a href=\"https://www.goodreads.com/book/show/38559855\" rel=\"nofollow\">here</a></i><br /><br />Das Böse hält keinen Winterschlaf.<br />Kathy Reichs auch nicht.<br /><br /><br />Was könnte frostiger sein als ein kanadischer Dezembersturm? Tempe Brennan, forensische Anthropologin in Montreal, wird an einem tristen Montagmorgen zu einem Fundort gerufen, der ihr das Blut in den Adern gefrieren lässt. Verscharrt in einem Kellergewölbe liegen die Leichen dreier junger Frauen. Nicht eine Gewebefaser, kein Fetzen Kleidung geben Aufschluss darüber, wann und warum diese Mädchen sterben mussten. Nur dank akribischer Ermittlungen und weiblicher Intuition kommt Tempe dem Mörder auf die Spur. Doch sie muss auf alles gefasst sein, denn ihr Gegner ist an Kaltblütigkeit nicht zu übertreffen …<br /><br /><br />Tempe Brennans siebter Fall.<br /><br /><br /><br /><br />']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(books_data.Description[books_data.Id == 1099555]) #Description with url and html tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf24f21-cdc1-4606-ae2f-9dbbac6380d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alternate Cover Edition can be found hereDas Böse hält keinen WinterschlafKathy Reichs auch nichtWas könnte frostiger sein als ein kanadischer Dezembersturm Tempe Brennan forensische Anthropologin in Montreal wird an einem tristen Montagmorgen zu einem Fundort gerufen der ihr das Blut in den Adern gefrieren lässt Verscharrt in einem Kellergewölbe liegen die Leichen dreier junger Frauen Nicht eine Gewebefaser kein Fetzen Kleidung geben Aufschluss darüber wann und warum diese Mädchen sterben mussten Nur dank akribischer Ermittlungen und weiblicher Intuition kommt Tempe dem Mörder auf die Spur Doch sie muss auf alles gefasst sein denn ihr Gegner ist an Kaltblütigkeit nicht zu übertreffen …Tempe Brennans siebter Fall']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "def remove_url(text):   \n",
    "    return re.sub(url_pattern, r'', text)\n",
    "\n",
    "html_pattern = re.compile('<[^>]*>')\n",
    "def clean_html_tags(text):\n",
    "    return re.sub(html_pattern, r'', text)\n",
    "\n",
    "punctuations = string.punctuation\n",
    "def remove_punctuations(text):\n",
    "    return text.translate(str.maketrans('', '', punctuations))\n",
    "\n",
    "books_data.Description = books_data.Description.apply(remove_url)\n",
    "books_data.Description = books_data.Description.apply(clean_html_tags)\n",
    "books_data.Description = books_data.Description.apply(remove_punctuations)\n",
    "\n",
    "# Result\n",
    "list(books_data.Description[books_data.Id == 1099555])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f5447-4551-41fd-8358-6c7e8e1e1c6a",
   "metadata": {},
   "source": [
    "## Convert Letter Case to Lower and Clip Extra Spaces\n",
    "- Before changing the letter case, assign missing **Publisher** some temporary string `unknown` to retain these missing values during string transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f92d3c-7f2a-405a-ae6a-d60af793530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data[[\"Publisher\"]] = books_data[[\"Publisher\"]].fillna(\"unknown\")\n",
    "books_data[[\"Name\", \"Authors\", \"Publisher\", \"Description\"]] = pd.concat([books_data[col].astype(str).str.lower().str.strip() \n",
    "                                                                             for col in [\"Name\", \"Authors\", \"Publisher\", \"Description\"]], \n",
    "                                                                            axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7219c-cff9-4d5e-9250-abb75980d380",
   "metadata": {},
   "source": [
    "## Remove Book Descriptions With Shorter Length.\n",
    "After removing extra spaces it is found that some book descriptions only had blank spaces and really short descriptions containing one or two words. Such words do not retain the semantic meaning of the description and l will remove books with such shorter descriptions (word count less than four). We will first remove empty descriptions to `NaN` and then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ffe3b0-bb01-441f-a498-7adf2a49470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'edition bilingue', 'anthology', 'achtzehn beispielhafte bildergeschichten', 'level a', '《洗澡》不是由一个主角贯连全部的小说，而是借一个政治运动作背景，写那个时期形形色色的知识分子。所以是个横断面；既没有史诗性的结构，也没有主角。本书第一部写新中国不拘一格收罗的人才，人物一一出场。第二部写这些人确实需要“洗澡”。第三部写运动中这群人各自不同的表现。“洗澡”没有得到预期的效果，原因是谁都没有自觉自愿。假如说，人是有灵性、有良知的动物，那么，人生一世，无非是认识自己，洗炼自己，自觉自愿地改造自己，除非甘心与禽兽无异。但是这又谈何容易呢？这部小说里，只有一两人自觉自愿地试图超拔自己。读者出于喜爱，往往把他们看作主角。', 'the understanding', '《文化、權力與國家1900—1942年的華北農村》是美國學者杜贊奇的名著。杜贊奇（prasenjit duara），早年就學於印度，後赴美國求學，師從著名漢學大師孔飛力，現任美國芝加哥大學歷史學系及東亞語言文明系教授。其著作除本書外，還有廣為學界選舉的《從民族國家拯救歷史》。此兩書使杜贊奇成為名聞國際的漢學家。本書是以鄉村的文化網絡為基本結構並考察其功能力，作者主要利用日本南滿鐵道株式會社調查部編撰的《中國慣行調查報告》、南開大學經濟研究所在20世紀二三十年代所做的社會調查材料，以及中外學者已有的研究成果，通過細致的個案研究，向我們展示了1900—1942年間華北農村社會的政治經濟文化的一般狀況。作者力圖打通歷史學與社會學的間隔，提出了「國家政權建設」和「權力的文化網絡」兩個中心概念。作者認為，「國家政權建設」是一種全球性現象，作為一個概念，同更古老的「資本主義」等概念一樣，具有深遠的分析性含義。「權力的文化網絡」概念則吸收了西方學術界有關文化研究的成果，反對一些現代化論者用單一社會體系或一套所謂的「中國價值觀」去理解中國的觀點，同時也反對認為價值觀點交互感應的功能主義論者的學說。最重要的一點是，作者在書中貫穿了這樣一種方法在考慮話語—主體—制度這三者對歷史的建構時，應加入許多外來事物和偶然因素，因為參與主體和主體性構成的不僅有話語，還有外來事物；而由主體構建的制度，還應包括制度本身的邏輯性和偶然性。本書曾先後榮獲1989年度的美國歷史學會費正清獎以及1900年度的亞洲研究學會列文森獎。', 'print on demand', 'grades 612', 'vol 1of 2', 'drama', 'collects daredevil 125', 'revised and updated', '本集共收《在私塾》、《往事》、《常德的船》、《凤凰》等10篇散文。', 'textformat02gt', 'none', 'bild wissensbibliothek', 'erlogen von loriot', 'ranma ½ 7', 'noel polk editor', 'book by', 'english and italian', 'haynes', '中古品につき多少のキズ・汚れ・日焼け等はありますが、状態は良好です。', 'twentytwo traditional rhymes', 'yasuhiro nakasone', 'undefined', 'poetry', 'recreation of landscape', '1593977484', 'abridged', 'one womanos charlottetown', 'publishers weekly', 'new'}\n"
     ]
    }
   ],
   "source": [
    "# Find description word count\n",
    "books_data[\"length\"] = [len(d.split()) for d in books_data['Description'].tolist()]\n",
    "\n",
    "print(set(books_data.Description[books_data.length.isin(range(0,4))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d15a6d05-2c3c-4d95-a427-489cb930f7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1001461</td>\n",
       "      <td>barbarism</td>\n",
       "      <td>poetry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24941</th>\n",
       "      <td>1062171</td>\n",
       "      <td>middlemarch: in half the time</td>\n",
       "      <td>abridged</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17626</th>\n",
       "      <td>1043889</td>\n",
       "      <td>to the nines (stephanie plum, #9)</td>\n",
       "      <td>1593977484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26421</th>\n",
       "      <td>1065801</td>\n",
       "      <td>the bird lovers</td>\n",
       "      <td>drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26889</th>\n",
       "      <td>1066895</td>\n",
       "      <td>凤凰集</td>\n",
       "      <td>本集共收《在私塾》、《往事》、《常德的船》、《凤凰》等10篇散文。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                               Name  \\\n",
       "636    1001461                          barbarism   \n",
       "24941  1062171      middlemarch: in half the time   \n",
       "17626  1043889  to the nines (stephanie plum, #9)   \n",
       "26421  1065801                    the bird lovers   \n",
       "26889  1066895                                凤凰集   \n",
       "\n",
       "                             Description  length  \n",
       "636                               poetry       1  \n",
       "24941                           abridged       1  \n",
       "17626                         1593977484       1  \n",
       "26421                              drama       1  \n",
       "26889  本集共收《在私塾》、《往事》、《常德的船》、《凤凰》等10篇散文。       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace empty strings of description with NaN\n",
    "books_data.Description = books_data.Description.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "books_data[books_data.length.isin(range(1,min_description_word_count+1))][[\"Id\", \"Name\", \"Description\", \"length\"]]\\\n",
    ".sort_values(by=[\"length\"], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "851da1b6-0a26-47b6-ae3c-5c8344f0d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data.dropna(subset=[\"Description\"], inplace=True)\n",
    "\n",
    "# Drop records with very short description\n",
    "books_data.drop(books_data.index[books_data.length.isin(range(0,min_description_word_count+1))], inplace = True)\n",
    "del books_data[\"length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76101a67-6713-4729-aacc-b35cbef0d377",
   "metadata": {},
   "source": [
    "## Drop Variants of the Same Book\n",
    "- Descriptions are repeated; this possibly could be due to different versions of the same book. Repeated values in **Authors, Publisher** can help in recommending books of the same author and publisher.\n",
    "- We see that the same books have different ISBN because an ISBN is assigned to each separate edition and variation of a publication. ISBN is like an identity number for each edition, imprint, impression or version of the same book. For example, an e-book, a paperback and a hardcover edition of the same book will each have a different ISBN (except reprintings).\n",
    "- Only keep variants where **Publisher** is not null, if Publisher is missing for all the variants then keep the first occurrence and delete rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbb67d82-fe5a-4135-a271-e0b00182250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert unknown to NaN\n",
    "books_data[\"Publisher\"] = books_data.Publisher.replace('unknown',np.nan)\n",
    "books_data = books_data.sort_values(by=\"Publisher\", na_position='last')\\\n",
    ".drop_duplicates(subset=[\"Name\", \"Authors\", \"Description\"], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9f290-fe3f-4089-bb79-43b7ecea7e0f",
   "metadata": {},
   "source": [
    "Though we have deleted rows with the same **Name, Authors** and **Description**, we still find books having duplicated Description. This happens due to minor textual changes in the **Name** of the book and also because certain **Description**s are repetitive for different books."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39d699-cf97-4c74-816b-8b34ceafbeae",
   "metadata": {},
   "source": [
    "## Extract and Remove Book Series Information from the Book Name\n",
    "- Remove irrelevant information from the name of the book to improve efficiency of the tokenization.\n",
    "- Book names with a hashtag following a number represents the edition of the book in a series. (Example: In book name blood captain (vampirates, #3), vampirates is the series name and #3 means its third book in the series.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a202a2-036b-4ebc-aeec-a5a24ed265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_pattern =  \"(?:[;]\\s*|\\(\\s*)([^\\(;]*\\s*#\\s*\\d+(?:\\.?\\d+|\\\\&\\d+|-?\\d*))\"\n",
    "def get_book_series_info(text):\n",
    "    series_info = re.findall(series_pattern, text)\n",
    "    if series_info:\n",
    "        series_info = \" \".join([i.replace(\" \", \"_\") for i in series_info])\n",
    "        return series_info\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "books_data['BookSeriesInfo'] = books_data.Name.apply(get_book_series_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5fc95-8e4c-4534-952b-4dce096ff99f",
   "metadata": {},
   "source": [
    "- As we are using regex there will be certain exceptions, for example it misses a book name with nested brackets case. The name of the book is \"Ranma 1/2, Vol. 28 (Ranma ½ (US 2nd), #28)\", it should extract series information as `Ranma ½ (US 2nd), #28]`, instead, it extracts `[US 2nd), #28]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec4e74-4f18-4f03-adee-4f5475e1da86",
   "metadata": {},
   "source": [
    "## Extract and Remove Book Series Information from the Book Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2b954ed-0407-4742-8d92-be0ca01942bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_remove_pattern = re.compile(\"(?:[\\(]\\s*[^\\(;]*\\s*#\\s*\\d+(?:\\.?\\d+|\\\\&\\d+|-?\\d*)(?:;|\\))|\\s*[^\\(;]*\\s*#\\s*\\d+(?:\\.?\\d+|\\\\&\\d+|-?\\d*)\\))\")       \n",
    "def remove_series_info(text):\n",
    "    return re.sub(series_remove_pattern, r'', text)\n",
    "\n",
    "books_data[\"Title\"]= books_data[\"Name\"].str.replace(series_remove_pattern, r'').str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e22330-05fc-4e04-ae73-d85d2ebbd0aa",
   "metadata": {},
   "source": [
    "## Impute Missing Language Information Using the Language of the Book Name\n",
    "**Language** feature has missing values. I will impute missing **Language** information using the language of the book **Name**. Language detection for thousands of records takes considerable time. I have already saved the results into a CSV `preprocessed.csv`. I will directly use that for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0a81a69-52f4-4516-998b-719b3188da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCat()\n",
    "\n",
    "def detect_language(text):\n",
    "    text = \" \".join(text.split()[:5])\n",
    "    if text.isnumeric():\n",
    "        return 'eng'\n",
    "    else:\n",
    "        return tc.guess_language(text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffbc6407-9bed-4ccc-980b-6752c4abb2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                    0\n",
       "Name                  0\n",
       "Authors               0\n",
       "ISBN                 87\n",
       "PublishYear           0\n",
       "Publisher           228\n",
       "Language              0\n",
       "Description           0\n",
       "BookSeriesInfo    32380\n",
       "Title                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"\"\"\n",
    " Takes longer time to process thousands records hence results are presaved in preprocessed.csv\n",
    " \"\"\"\n",
    "# ddf = dd.from_pandas(books_data, npartitions=4*multiprocessing.cpu_count()) \n",
    "# books_data[\"Language\"] = ddf.map_partitions(lambda df: df.apply(lambda x: detect_language(x['Name']) if pd.isna(x['Language']) else x['Language'], axis=1)).compute() \n",
    "# books_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49948f2b-7f2d-4c68-bd12-e0d3ab7d6029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Authors</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Language</th>\n",
       "      <th>Description</th>\n",
       "      <th>BookSeriesInfo</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>1020396</td>\n",
       "      <td>the gospel of john</td>\n",
       "      <td>francis j. moloney</td>\n",
       "      <td>0814658067</td>\n",
       "      <td>1998</td>\n",
       "      <td>\"michael glazier\"</td>\n",
       "      <td>eng</td>\n",
       "      <td>what sets this commentary on the fourth gospel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the gospel of john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29576</th>\n",
       "      <td>1073868</td>\n",
       "      <td>hanslick on the musically beautiful: sixteen l...</td>\n",
       "      <td>geoffrey payzant</td>\n",
       "      <td>1877275530</td>\n",
       "      <td>2003</td>\n",
       "      <td>1-877275-49-2</td>\n",
       "      <td>eng</td>\n",
       "      <td>the sixteen lectures by geoffrey payzant in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hanslick on the musically beautiful: sixteen l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10277</th>\n",
       "      <td>1025976</td>\n",
       "      <td>microserfs</td>\n",
       "      <td>douglas coupland</td>\n",
       "      <td>2264024003</td>\n",
       "      <td>1997</td>\n",
       "      <td>10/18</td>\n",
       "      <td>fre</td>\n",
       "      <td>génération x 1018 n° 2508 qui a connu un gros ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>microserfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18484</th>\n",
       "      <td>1045943</td>\n",
       "      <td>courir avec des ciseaux</td>\n",
       "      <td>augusten burroughs</td>\n",
       "      <td>2264043784</td>\n",
       "      <td>2006</td>\n",
       "      <td>10/18</td>\n",
       "      <td>fre</td>\n",
       "      <td>roman autobiographique choc courir avec des ci...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courir avec des ciseaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>1027805</td>\n",
       "      <td>affinités</td>\n",
       "      <td>sarah waters</td>\n",
       "      <td>2264043628</td>\n",
       "      <td>2006</td>\n",
       "      <td>10/18</td>\n",
       "      <td>fre</td>\n",
       "      <td>pour tromper son ennui une demoiselle de la bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affinités</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                               Name  \\\n",
       "8222   1020396                                 the gospel of john   \n",
       "29576  1073868  hanslick on the musically beautiful: sixteen l...   \n",
       "10277  1025976                                         microserfs   \n",
       "18484  1045943                            courir avec des ciseaux   \n",
       "11093  1027805                                          affinités   \n",
       "\n",
       "                  Authors        ISBN  PublishYear          Publisher  \\\n",
       "8222   francis j. moloney  0814658067         1998  \"michael glazier\"   \n",
       "29576    geoffrey payzant  1877275530         2003      1-877275-49-2   \n",
       "10277    douglas coupland  2264024003         1997              10/18   \n",
       "18484  augusten burroughs  2264043784         2006              10/18   \n",
       "11093        sarah waters  2264043628         2006              10/18   \n",
       "\n",
       "      Language                                        Description  \\\n",
       "8222       eng  what sets this commentary on the fourth gospel...   \n",
       "29576      eng  the sixteen lectures by geoffrey payzant in th...   \n",
       "10277      fre  génération x 1018 n° 2508 qui a connu un gros ...   \n",
       "18484      fre  roman autobiographique choc courir avec des ci...   \n",
       "11093      fre  pour tromper son ennui une demoiselle de la bo...   \n",
       "\n",
       "      BookSeriesInfo                                              Title  \n",
       "8222             NaN                                 the gospel of john  \n",
       "29576            NaN  hanslick on the musically beautiful: sixteen l...  \n",
       "10277            NaN                                         microserfs  \n",
       "18484            NaN                            courir avec des ciseaux  \n",
       "11093            NaN                                          affinités  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_preview = books_data.head(5).copy()\n",
    "ddf = dd.from_pandas(temp_preview, npartitions=4*multiprocessing.cpu_count()) \n",
    "temp_preview[\"Language\"] = ddf.map_partitions(lambda df: df.apply(lambda x: detect_language(x['Name']) if pd.isna(x['Language']) else x['Language'], axis=1)).compute() \n",
    "temp_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b19e97-230c-4e09-9d3a-192e9ce4f9d6",
   "metadata": {},
   "source": [
    "## Remove Double Quotes from Publisher Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65478a6d-c7d5-4d99-8616-dd8522fb99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data[\"Publisher\"] = books_data[\"Publisher\"].str.replace('\"','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde8be9-7450-4b08-818f-37b42f07c7cf",
   "metadata": {},
   "source": [
    "## Transform Book and Author Names into Single Token\n",
    "- Merge first and last name of authors (with `_`) so that two authors with same first or last name are not considered same when the tokenization happens.\n",
    "- Also merge name of the book so that it is considered as single token during the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74a06864-1a2d-4b6f-aada-92d9d56d565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Authors</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Language</th>\n",
       "      <th>Description</th>\n",
       "      <th>BookSeriesInfo</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>1020396</td>\n",
       "      <td>the gospel of john</td>\n",
       "      <td>francis_j._moloney</td>\n",
       "      <td>0814658067</td>\n",
       "      <td>1998</td>\n",
       "      <td>michael_glazier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what sets this commentary on the fourth gospel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the gospel of john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29576</th>\n",
       "      <td>1073868</td>\n",
       "      <td>hanslick on the musically beautiful: sixteen l...</td>\n",
       "      <td>geoffrey_payzant</td>\n",
       "      <td>1877275530</td>\n",
       "      <td>2003</td>\n",
       "      <td>1-877275-49-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the sixteen lectures by geoffrey payzant in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hanslick on the musically beautiful: sixteen l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10277</th>\n",
       "      <td>1025976</td>\n",
       "      <td>microserfs</td>\n",
       "      <td>douglas_coupland</td>\n",
       "      <td>2264024003</td>\n",
       "      <td>1997</td>\n",
       "      <td>10/18</td>\n",
       "      <td>fre</td>\n",
       "      <td>génération x 1018 n° 2508 qui a connu un gros ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>microserfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18484</th>\n",
       "      <td>1045943</td>\n",
       "      <td>courir avec des ciseaux</td>\n",
       "      <td>augusten_burroughs</td>\n",
       "      <td>2264043784</td>\n",
       "      <td>2006</td>\n",
       "      <td>10/18</td>\n",
       "      <td>fre</td>\n",
       "      <td>roman autobiographique choc courir avec des ci...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courir avec des ciseaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>1027805</td>\n",
       "      <td>affinités</td>\n",
       "      <td>sarah_waters</td>\n",
       "      <td>2264043628</td>\n",
       "      <td>2006</td>\n",
       "      <td>10/18</td>\n",
       "      <td>fre</td>\n",
       "      <td>pour tromper son ennui une demoiselle de la bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affinités</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                               Name  \\\n",
       "8222   1020396                                 the gospel of john   \n",
       "29576  1073868  hanslick on the musically beautiful: sixteen l...   \n",
       "10277  1025976                                         microserfs   \n",
       "18484  1045943                            courir avec des ciseaux   \n",
       "11093  1027805                                          affinités   \n",
       "\n",
       "                  Authors        ISBN  PublishYear        Publisher Language  \\\n",
       "8222   francis_j._moloney  0814658067         1998  michael_glazier      NaN   \n",
       "29576    geoffrey_payzant  1877275530         2003    1-877275-49-2      NaN   \n",
       "10277    douglas_coupland  2264024003         1997            10/18      fre   \n",
       "18484  augusten_burroughs  2264043784         2006            10/18      fre   \n",
       "11093        sarah_waters  2264043628         2006            10/18      fre   \n",
       "\n",
       "                                             Description BookSeriesInfo  \\\n",
       "8222   what sets this commentary on the fourth gospel...            NaN   \n",
       "29576  the sixteen lectures by geoffrey payzant in th...            NaN   \n",
       "10277  génération x 1018 n° 2508 qui a connu un gros ...            NaN   \n",
       "18484  roman autobiographique choc courir avec des ci...            NaN   \n",
       "11093  pour tromper son ennui une demoiselle de la bo...            NaN   \n",
       "\n",
       "                                                   Title  \n",
       "8222                                  the gospel of john  \n",
       "29576  hanslick on the musically beautiful: sixteen l...  \n",
       "10277                                         microserfs  \n",
       "18484                            courir avec des ciseaux  \n",
       "11093                                          affinités  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data[\"Authors\"] = books_data[\"Authors\"].str.strip().str.replace(' ','_')\n",
    "books_data[\"Publisher\"] = books_data[\"Publisher\"].str.strip().str.replace(' ','_')\n",
    "books_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff6e2c-caa8-4306-a686-629e1415b8d5",
   "metadata": {},
   "source": [
    "## Merge All the Textual Summary into a Single Summary Column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de4fbf-76ca-4f47-a600-970d6f7efc1f",
   "metadata": {},
   "source": [
    "Combine all the book information related tokens such as book series information, authors, publisher, language, publish year into a single summary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f77a0f57-a334-4053-a681-c492bd475fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data[\"bow\"] = eda_data[[\"BookSeriesInfo\", 'Authors', 'Publisher', 'Language']].fillna('').agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44cf021b-f99e-4f51-9f1e-667c9d239618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jo_ann_mcnamara duke_university_press_books eng'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data.bow.iloc[8375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce7e77-7ded-44af-befd-51c4c321e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "# books_data.to_csv(\"data/preprocessed.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfc007-f9ff-4267-886b-adcccaf16613",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Feature Engineering\n",
    "<span style=\"font-size:1.5em;\">Notebook:</span> [<span style=\"font-size:1.5em;\">feature_engineering.ipynb</span>](feature_engineering.ipynb)\n",
    "\n",
    "Extracted keywords are stored are stored in `data/keywords.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f330346d-5242-4ff2-bdd2-b57f7af4386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Language</th>\n",
       "      <th>Description</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020396</td>\n",
       "      <td>the gospel of john</td>\n",
       "      <td>eng</td>\n",
       "      <td>what sets this commentary on the fourth gospel...</td>\n",
       "      <td>francis_j._moloney michael_glazier eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073868</td>\n",
       "      <td>hanslick on the musically beautiful: sixteen l...</td>\n",
       "      <td>eng</td>\n",
       "      <td>the sixteen lectures by geoffrey payzant in th...</td>\n",
       "      <td>geoffrey_payzant 1-877275-49-2 eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1025976</td>\n",
       "      <td>microserfs</td>\n",
       "      <td>fre</td>\n",
       "      <td>génération x 1018 n° 2508 qui a connu un gros ...</td>\n",
       "      <td>douglas_coupland 10/18 fre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1045943</td>\n",
       "      <td>courir avec des ciseaux</td>\n",
       "      <td>fre</td>\n",
       "      <td>roman autobiographique choc courir avec des ci...</td>\n",
       "      <td>augusten_burroughs 10/18 fre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1027805</td>\n",
       "      <td>affinités</td>\n",
       "      <td>fre</td>\n",
       "      <td>pour tromper son ennui une demoiselle de la bo...</td>\n",
       "      <td>sarah_waters 10/18 fre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                               Name Language  \\\n",
       "0  1020396                                 the gospel of john      eng   \n",
       "1  1073868  hanslick on the musically beautiful: sixteen l...      eng   \n",
       "2  1025976                                         microserfs      fre   \n",
       "3  1045943                            courir avec des ciseaux      fre   \n",
       "4  1027805                                          affinités      fre   \n",
       "\n",
       "                                         Description  \\\n",
       "0  what sets this commentary on the fourth gospel...   \n",
       "1  the sixteen lectures by geoffrey payzant in th...   \n",
       "2  génération x 1018 n° 2508 qui a connu un gros ...   \n",
       "3  roman autobiographique choc courir avec des ci...   \n",
       "4  pour tromper son ennui une demoiselle de la bo...   \n",
       "\n",
       "                                       bow  \n",
       "0   francis_j._moloney michael_glazier eng  \n",
       "1       geoffrey_payzant 1-877275-49-2 eng  \n",
       "2               douglas_coupland 10/18 fre  \n",
       "3             augusten_burroughs 10/18 fre  \n",
       "4                   sarah_waters 10/18 fre  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch preprocessed cleaned data\n",
    "fe_data = pd.read_csv(\"data/preprocessed.csv\", usecols=[\"Id\", \"Name\", \"Language\", \"Description\", \"bow\"])\n",
    "fe_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4db27-61ce-40b7-a8fa-aaa0050b173c",
   "metadata": {},
   "source": [
    "## Keyword Extraction Using KeyBERT\n",
    "- Use [_keyBERT_](https://github.com/MaartenGr/KeyBERT) to extract relevant keywords from the **Description**. It is developed and maintained by Maarten Grootendorst. As stated in its document **_KeyBERT_** uses BERT-embeddings and cosine similarity to find the sub-phrases in a document that are the most similar to the document itself.  \n",
    "- keyBERT retains the semantic aspect of a text by using pre-trained BERT models to create first document embeddings and later keyword embeddings. By default it uses `all-MiniLM-L6-v2` sentence-transformer model from HuggingFace🤗 transformer.  But depending on the need, different [pretrained models](https://www.sbert.net/docs/pretrained_models.html) can be selected. For keyword extraction it uses Bag-Of-Words techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34dd02-8f8d-4c3f-bcd9-1b9b7580c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "\n",
    "def get_keywords(text):\n",
    "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=\"english\")\n",
    "    keywords = \" \".join([k[0] for k in keywords])\n",
    "    return keywords\n",
    "\n",
    "fe_data[\"keywords\"] = fe_data.Description.apply(get_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0980dbb3-9778-49b9-b893-113e9737714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12                  memphis egypt delta governor thebes\n",
       "15               proverb picket bells christmas stories\n",
       "21                      emma paris french shes sullivan\n",
       "25    moomintroll comet moominvalley adventures adve...\n",
       "27                     acheron greeks trojan troy helen\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_data.keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29244e2-7536-4271-8601-08e2054db7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_data[\"keywords\"] = fe_data[['bow', 'keywords']].fillna('').agg(' '.join, axis=1)\n",
    "fe_data.drop(['bow', 'Description'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b301b-8623-4cbf-8566-ef98ebda31d8",
   "metadata": {},
   "source": [
    "## Remove duplicated Book Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e341162-cc55-4a23-a102-5b67bef53c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_data = fe_data.drop_duplicates(subset=[\"Name\"], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4107b71-df40-4ddd-8c23-162abbf5b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_data.to_csv(\"data/keywords.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26013de9-f621-42a0-9252-aacb0663a020",
   "metadata": {},
   "source": [
    "# Text Representation\n",
    "## Vectorization using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33b4dc-5c22-4afe-bd22-843bead63006",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264600a-f3a8-4919-b181-4233e839cd65",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb4799-6fd8-4ed0-a0a5-cf9c11e277ec",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
